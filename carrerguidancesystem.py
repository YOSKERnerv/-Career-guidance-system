# -*- coding: utf-8 -*-
"""CarrerGuidanceSystem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/YOSKERnerv/-Career-guidance-system/blob/main/CarrerGuidanceSystem.ipynb

# **Carrer Guidance System**

# import dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

df = pd.read_csv(r"https://raw.githubusercontent.com/YOSKERnerv/-Career-guidance-system/refs/heads/main/student-scores-with-stream.csv")
df

"""# **Data Preprocessing**

## Driving Insights
"""

df.info()

df.describe()

"""### Handling the index"""

df.set_index("id", inplace=True)
df

"""### Removing null values"""

df.fillna(df.mean(numeric_only=True), inplace=True)
numeric_cols = df.select_dtypes(include=['number']).columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
df

"""### **Handling the boolean and object data**

### Bollean
"""

for col in df.select_dtypes(include=['bool']).columns:
    df[col] = df[col].astype(int)
df

"""### Dropping the unnessary data"""

df.drop(df.columns[0:4], axis=1, inplace=True)
df

"""## Converting the object into numeric data"""

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

df["Hobbies & Interests"] = label_encoder.fit_transform(df["Hobbies & Interests"])
df["career_aspiration"] = label_encoder.fit_transform(df["career_aspiration"])
df["preferred learning method"] = label_encoder.fit_transform(df["preferred learning method"])
df

"""# **Pre Model Processing**

### making labels
"""

label_encoder = LabelEncoder()
df["Recommended Stream"] = label_encoder.fit_transform(df["Recommended Stream"])
df

"""### Normalizing and Seperating the data"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X = df.drop(columns=["Recommended Stream"])  # Exclude label column
y = df["Recommended Stream"]  # Target variable

X_normalized = scaler.fit_transform(X)

"""### Spliting the data(test and train)"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=42)

"""# **Model Building**

## **Random Forest**

### Train the model
"""

from sklearn.ensemble import RandomForestClassifier

# Initialize and train the model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred_rf = rf_model.predict(X_test)

"""### Evaluate the model"""

from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

accuracy_rf = accuracy_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf, average='weighted')
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)

# Print Results
print(f"Random Forest Accuracy: {accuracy_rf:.2f}")
print(f"Random Forest F1 Score: {f1_rf:.2f}")
print("Random Forest Confusion Matrix:")
print(conf_matrix_rf)

"""## **Support Vector Machine(SVM)**"""

from sklearn.svm import SVC
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

# Train SVM Model
svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train, y_train)

# Make Predictions
y_pred_svm = svm_model.predict(X_test)

# Evaluate the model
accuracy_svm = accuracy_score(y_test, y_pred_svm)
f1_svm = f1_score(y_test, y_pred_svm, average='weighted')
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)

# Print Results
print(f"SVM Accuracy: {accuracy_svm:.2f}")
print(f"SVM F1 Score: {f1_svm:.2f}")
print("SVM Confusion Matrix:")
print(conf_matrix_svm)

# Visualization
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_svm, annot=True, cmap="Blues", fmt="d", xticklabels=set(y_test), yticklabels=set(y_test))
plt.title("SVM Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""## **Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

# Train Decision Tree Model
dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)
dt_model.fit(X_train, y_train)

# Make Predictions
y_pred_dt = dt_model.predict(X_test)

# Evaluate the model
accuracy_dt = accuracy_score(y_test, y_pred_dt)
f1_dt = f1_score(y_test, y_pred_dt, average='weighted')
conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)

# Print Results
print(f"Decision Tree Accuracy: {accuracy_dt:.2f}")
print(f"Decision Tree F1 Score: {f1_dt:.2f}")
print("Decision Tree Confusion Matrix:")
print(conf_matrix_dt)

# Decision Tree Visualization (FIXED)
plt.figure(figsize=(12, 8))
plot_tree(dt_model, filled=True, feature_names=df.columns[:-1], class_names=dt_model.classes_.astype(str))
plt.title("Decision Tree Visualization")
plt.show()

"""## **XGboost**"""

from xgboost import XGBClassifier

# Train XGBoost Model
xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)

# Make Predictions
y_pred_xgb = xgb_model.predict(X_test)

# Evaluate the model
accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')
conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)

# Print Results
print(f"XGBoost Accuracy: {accuracy_xgb:.2f}")
print(f"XGBoost F1 Score: {f1_xgb:.2f}")
print("XGBoost Confusion Matrix:")
print(conf_matrix_xgb)

# Visualization
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_xgb, annot=True, cmap="Greens", fmt="d", xticklabels=set(y_test), yticklabels=set(y_test))
plt.title("XGBoost Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

!pip install flask
!pip install flask-cors
!pip install joblib
!pip install numpy
!pip install pandas
!pip install requests

import joblib

# Save the trained model
joblib.dump(rf_model, "career_model.pkl")

# Save the scaler if used
joblib.dump(scaler, "scaler.pkl")

!pip install -q joblib numpy pandas requests

"""# Api Integeration"""

import google.generativeai as genai
import json
import pandas as pd
import numpy as np
from google.colab import userdata  # For securely storing API keys

# Configure Gemini API
GEMINI_API_KEY = "AIzaSyDl1rAnDAL53H1DOxnD7DGbXezt3xrCnGE"
genai.configure(api_key=GEMINI_API_KEY)

# ðŸŽ¯ Sample Student Data Format
def get_sample_student_data():
    return {
        "Hobbies & Interests": "Painting",
        "Part-Time Job": "None",
        "Absence Days": 5,
        "Extracurricular Activities": "Debate Club",
        "Weekly Self-Study Hours": 10,
        "Career Aspiration": "Doctor",
        "Math Score": 85,
        "History Score": 78,
        "Physics Score": 80,
        "Chemistry Score": 72,
        "Biology Score": 60,
        "English Score": 75,
        "Economics Score": 82,
        "Geography Score": 70,
        "Computer Science Score": 90,
        "Analytical Thinking Score": 85,
        "Logical Reasoning Score": 88,
        "Psychology Score": 65,
        "Preferred Learning Method": "Visual Learning"
    }

# Function to Get Career Prediction
def get_career_prediction(student_data):
    json_data = json.dumps(student_data, indent=4)
    prompt = f"""
    You are an AI career advisor. Predict the most suitable career stream
    (Technology, Medical, Commerce, Arts) based on the following student data:

    {json_data}
    """
    model = genai.GenerativeModel("gemini-2.0-flash-lite")
    response = model.generate_content(prompt)
    return response.text

def get_follow_up_advice(student_data, user_query):
    json_data = json.dumps(student_data, indent=4)
    prompt = f"""
    The user has the following background:
    {json_data}

    The user is asking:
    "{user_query}"

    Provide logical, structured, point-wise career advice. If applicable, show a table comparing different career options.
    """
    model = genai.GenerativeModel("gemini-2.0-flash-lite")
    response = model.generate_content(prompt)
    return response.text

student_data = get_sample_student_data()
career_prediction = get_career_prediction(student_data)
print("Predicted Career Stream:", career_prediction)

user_query = "I love painting but my career prediction is Technology. Can I still pursue painting?"
advice = get_follow_up_advice(student_data, user_query)
print("\nFollow-Up Career Advice:")
print(advice)

"""# New Section"""

!pip install flask-cors

from flask import Flask, request, jsonify
from flask_cors import CORS

app = Flask(__name__)
CORS(app)  # Enable CORS for frontend-backend communication

@app.route('/submit', methods=['POST'])
def receive_data():
    try:
        data = request.get_json()  # Get JSON data from the frontend
        if not data:
            return jsonify({"error": "No data received"}), 400

        print("Received Data:", data)  # Log received data

        # You can integrate this with your career guidance model here

        return jsonify({"message": "Data received successfully"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '_main_':
    app.run(host='0.0.0.0',port=5000,debug=True)

